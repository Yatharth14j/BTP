{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb11f242-322f-4b5d-8e1c-db9a5e3e6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import pytesseract \n",
    "from pytesseract import image_to_string\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "%run helper-extractingVideos.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a00fbbe9-e153-4c28-8ea1-59c9f1fc18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_video(filePath,videoName,template,templateRes):\n",
    "        # Open the video using OpenCV\n",
    "    \n",
    "    desired_width = 1631\n",
    "    desired_height = 907\n",
    "    cap = cv2.VideoCapture(filePath)\n",
    "    #,apiPreference=cv2.CAP_ANY,params=[\n",
    "    #cv2.CAP_PROP_FRAME_WIDTH,desired_width ,\n",
    "    #cv2.CAP_PROP_FRAME_HEIGHT, desired_height])\n",
    "    \n",
    "    #cap.set(cv2.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    #cap.set(cv2.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "    fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"FPS:\",fps)\n",
    "    minToSkip=11\n",
    "    framesToSkip=fps*60*minToSkip\n",
    "    framesToSkipEverySec=fps-1\n",
    "    currentFrame=0\n",
    "    currentFrameInSec=0\n",
    "    jumpStarted=False\n",
    "    sno=1\n",
    "    row={}#changed\n",
    "\n",
    "    # Initialize a list to store the scores\n",
    "\n",
    "    print(\"start\")\n",
    "\n",
    "    oldText=\"old\"\n",
    "    # Process each frame of the video\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, frame = cap.read()\n",
    "        currentFrame+=1\n",
    "        currentFrameInSec+=1\n",
    "        if currentFrame<framesToSkip :\n",
    "            if currentFrame%(fps*60)==0:\n",
    "                print(currentFrame//(fps*60) ,\" min(s) Skipped\")\n",
    "            continue\n",
    "        if currentFrame//(fps*60)<minToSkip:\n",
    "            continue\n",
    "        if currentFrameInSec<framesToSkipEverySec:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # Break the loop if the video has ended\n",
    "        if not ret:\n",
    "            print(\"completed\")\n",
    "            break\n",
    "\n",
    "        current_pos = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        total_seconds = int(current_pos // 1000)\n",
    "        minutes = total_seconds // 60\n",
    "        seconds = total_seconds % 60\n",
    "        timeInVideo =f\"{minutes} minutes and {seconds} seconds\"\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "       \n",
    "    \n",
    "        \n",
    "        if not jumpStarted:\n",
    "            cropped=extract_frame(frame,template)\n",
    "            print(\"Cropped :\" , cropped)\n",
    "            if cropped:\n",
    "                jumpStarted=True\n",
    "            #plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "                row['Time'] = timeInVideo\n",
    "                print(timeInVideo,\" jump started\")\n",
    "                if 'Time' in row:  # Check if 'Time' key exists in row\n",
    "                # Extract minutes and seconds from time duration string\n",
    "                    time_str = row['Time']\n",
    "                    minutes_str, seconds_str = re.match(r'(\\d+) minutes and (\\d+) seconds', time_str).groups()\n",
    "                # Convert minutes and seconds to integers\n",
    "                    minutes = int(minutes_str)\n",
    "                    seconds = int(seconds_str)\n",
    "                # Calculate total seconds\n",
    "                    totalSeconds = minutes * 60 + seconds            \n",
    "\n",
    "      \n",
    "        if jumpStarted:\n",
    "            cropped=extract_frame(frame,templateRes)\n",
    "            if cropped:\n",
    "                jumpStarted = False\n",
    "                print(timeInVideo,\" jump scores announced\")\n",
    "                #plt.imshow(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "                extract_clip(filePath,'ExtractedVideos/'+str(sno)+'_'+videoName+'.mp4',totalSeconds,int(total_seconds))\n",
    "                sno+=1\n",
    "                #print(text)\n",
    "                print(row)\n",
    "                #save_data(row,\"scores\")\n",
    "\n",
    "        \n",
    "\n",
    "        currentFrameInSec=0    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77810f3b-e969-44b7-bb85-3d3bc043af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 29.97002997002997\n",
      "start\n",
      "Length of loc[0]: 0\n",
      "Length of loc[1]: 0\n",
      "Cropped : False\n",
      "Length of loc[0]: 445\n",
      "Length of loc[1]: 445\n",
      "Cropped : True\n",
      "11 minutes and 0 seconds  jump started\n",
      "Length of loc[0]: 6992\n",
      "Length of loc[1]: 6992\n",
      "11 minutes and 0 seconds  jump scores announced\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x59191d0d::Set<3,4,-1>,struct cv::impl::A0x59191d0d::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m templateLondon \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelperImages/template1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m      2\u001b[0m templateResLondon \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelperImages/template2.png\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m----> 3\u001b[0m extract_from_video(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo/Women\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_High_Jump_Final_Tokyo_Replays.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWomen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_High_Jump_Final_Tokyo_Replays\u001b[39m\u001b[38;5;124m\"\u001b[39m,templateLondon,templateResLondon)\n",
      "Cell \u001b[1;32mIn[12], line 86\u001b[0m, in \u001b[0;36mextract_from_video\u001b[1;34m(filePath, videoName, template, templateRes)\u001b[0m\n\u001b[0;32m     84\u001b[0m jumpStarted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(timeInVideo,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m jump scores announced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(cropped, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[0;32m     87\u001b[0m extract_clip(filePath,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtractedVideos/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(sno)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mvideoName\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m,totalSeconds,\u001b[38;5;28mint\u001b[39m(total_seconds))\n\u001b[0;32m     88\u001b[0m sno\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x59191d0d::Set<3,4,-1>,struct cv::impl::A0x59191d0d::Set<0,2,5>,4>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n"
     ]
    }
   ],
   "source": [
    "templateLondon = cv2.imread('helperImages/template1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "templateResLondon = cv2.imread('helperImages/template2.png', cv2.IMREAD_GRAYSCALE)\n",
    "extract_from_video(\"video/Women's_High_Jump_Final_Tokyo_Replays.mp4\",\"Women's_High_Jump_Final_Tokyo_Replays\",templateLondon,templateResLondon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e9c59-ef99-4111-9b22-b91c952c79b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
